{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee35b11f-8024-4644-81cc-8779bcf25c2e",
   "metadata": {},
   "source": [
    "# Tutorial Project OutLine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c099836d-45e6-49a3-97e0-2e01d7948815",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- ML Project Scoping\n",
    "    - Identify The Scope of the Project's Problem Space and it's qualities\n",
    "    - Identify The Scope of the Project's Solution Space and it's qualities\n",
    "- Project POC Prep\n",
    "    - Installing libs\n",
    "    - Remove Old Files\n",
    "    - Import libs\n",
    "- ML Steps:\n",
    "    1. Download and load data\n",
    "    2. Dataset Exploration with Dataset Summarries and Visualizations\n",
    "    3. Select Preprocessing Steps\n",
    "    4. Model Selection, Hyperparameter Tuning, Monitoring Training\n",
    "    5. (Model data drift Testing)   \n",
    "    6. (Model Serving and Monitoring)\n",
    "- Development Steps:\n",
    "    1. Hard code a bare bones proof-of-concept (POC) for an ML Project, within the identified project scope, in a single jupyter notebook file. \n",
    "    2. Define functions for repeatable lines of code, define variables for controling previously hardcoded settings,improve naming conventions\n",
    "    3. Add variables to control previously hard coded settings\n",
    "    4. move functions into seperate files to shorten and siplify the main file. \n",
    "    5. Add or update Documentation\n",
    "    6. Add more Features to the project That are relavent to the identified project scope starting from step one if more improvements are needed\n",
    "- Project Management Steps:\n",
    "    - Setup a Project Dashboard for the github repo.\n",
    "    - add meaningful views to the dashboard to help orginize the project.\n",
    "    - setup auto email alerts for team members assigned to issues when updates are posted.\n",
    "    - Add issues and set the priority, size, sprint, labels, tags, and more if needed.\n",
    "    - Set and enforce standards for team members posting to the project dashboard.\n",
    "    - Set Rules for the repo to protect the main branch from updates without reviews from more than one person\n",
    "    - Manually assign project issues for team members to work on or allow self assigning issues for a more hands free approach to managing the team.\n",
    "    - Regularly sceduled meetings with your team and with other managers from other departments.\n",
    "    - Allways encourage team members to ask questions for clarity on the goal of a tasks and to ask for more directions if they get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd16a947-985b-4a3a-913f-991b498e3de8",
   "metadata": {},
   "source": [
    "# ML Project Scoping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edb7877-1e7d-43a2-b3cf-dcf8a17f723d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Identify The Scope of the Project's Problem Space and it's qualities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b17e8da-2c4e-4e14-bb53-103dd1da3c15",
   "metadata": {},
   "source": [
    "- what tyoe of data are you working with?\n",
    "    - Structured or unstructured?\n",
    "    - labeled or unlabeled? (for supervised and unsupervised learning models and methods)\n",
    "    - shift invariant features? examples include: sound (time), images(space), video(time and space)\n",
    "    - Time Series data? examples include: text, events, sound, video \n",
    "- What task is your model going to be performing?\n",
    "    - classification\n",
    "    - linear regresion\n",
    "    - segmentation\n",
    "    - diffusion content generation\n",
    "    - combinations of the above options\n",
    "- how relavent is each of the dataset's features in determining the output task and how are the features related?\n",
    "    - should you be worried about feature selection or dimentionality reduction?\n",
    "    - have you considered feature engineering options?\n",
    "    - is there any missing info in any of your examples?\n",
    "- how many examples does your dataset have?\n",
    "- Are there known class imbalence or data drift problems? do you need to explore your data or consult a domain expert to find out?\n",
    "- Are there more data that you can aquire?\n",
    "    - internal sources: What other data features could be useful to add but are either not currently being recorded or are being recorded somewhere else but not in the database you are using?\n",
    "    - external sources: open source datasets, dataset venders, and web scaping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddc0979-9d88-482f-8533-0adbabb99ba6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Identify the Scope of the Project's Solution Space and it's qualities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6debc1-6440-4741-aebd-1d43eb1a7620",
   "metadata": {},
   "source": [
    "- Identify and ML and deep ml models that are well suited for the Scope of the Problem Space and it's qualities.\n",
    "- Identify checkpoints of deep models from the solution space that were previously trained for different tasks that could be used for transfer learning.\n",
    "- Identify preprocessing options that are well suited for the scope of the Problem Space and Solution Space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c12da4c-8893-4bbf-b6e3-050d04f8c268",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Project Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e9f0b-ca07-4003-be7f-e2018b3d6b16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Base Requirements:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ca1d8b-aace-4f52-9376-866fc2351916",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Follow tensorflow install guide. Some commands my be different depending on your OS. \n",
    "\n",
    "I used Windows so if you are using linux, update the commands in the \"Remove Old Files\" section for your OS. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade99eb8-21e5-4f2e-ab30-11d58a7c12a0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Installing libs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d11c5ca-5018-4657-9a4c-f4410df67b5b",
   "metadata": {},
   "source": [
    "create envirnment... add this later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b526deb-6590-48e4-8ee4-9ba16715e3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add env creation here..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed8b5d2-0a35-40f6-83ef-8539c4aebffd",
   "metadata": {},
   "source": [
    "start env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31307e72-ba57-487a-96e2-528365bf98fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Scripts\\Activate.ps1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f9d2ef-e5d5-4056-9af0-5e36ca9c1233",
   "metadata": {},
   "outputs": [],
   "source": [
    "#c:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Scripts\\python.exe -m pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95493b4-d67c-4738-8a12-4525ece4a76f",
   "metadata": {},
   "source": [
    "- You can update this later to use a requirements.txt file.\n",
    "- easy to save and install with pip commands\n",
    "- can hide in repo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b0130b-a465-416b-97ee-d1e6f25b9d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip freeze > requirements.txt\n",
    "#pip install -r \"C:Users\\rg\\MLProjTutorial\\requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e352f3f4-0f0a-4e46-9630-9861667fe478",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Remove Old Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6f8595-357d-48d9-bcd0-9e7e91975341",
   "metadata": {},
   "source": [
    "Clear out the old logs and saves with cmd commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23a7d4cc-3233-4d7c-8271-45452fa9f0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmdir /s /q C:\\Users\\gilbr\\ML_Proj_Code\\logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76a462f-6950-493c-b0ed-0142ddadc5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmdir /Q /S C:\\Users\\gilbr\\ML_Proj_Code\\saves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b5e716-1294-4764-9797-4c09839494c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir C:\\Users\\gilbr\\ML_Proj_Code\\saves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac035929-92ce-4710-b931-fcc4b894281c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23f44bdf-4941-48fe-94e8-9fc9f9d169a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "TensorFlow version: 2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import keras\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import datetime\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381cd117-7bcf-4d73-b72d-453b9cdf794a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# ML Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c0bd44-3a62-405c-b4de-66bfe2ac4eab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download and load data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a4047d-92dc-40cf-b958-eebb5bb9369c",
   "metadata": {},
   "source": [
    "For this project we will use the MNIST Dataset from Tensorflow.\n",
    "\n",
    "In other projects this step could also involve:\n",
    "- Querrying data from a database with SQL and or reading data from a file or files in a directory.\n",
    "- loading data into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9420e66-6236-4f09-b104-4d6c953ad574",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e043e-f608-4afb-bd10-e59cce72f2e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Dataset Exploration with Dataset Summarries and Visualizations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230f1992-ed6b-4009-aca0-f5130ce322f3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Part 1: Print out basic dataset info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454aea3b-953e-4f41-8028-7cc5fea3962c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping: print(\"x_train:\") print(x_train) print()\n",
      "\n",
      "Traning Image Shape:\n",
      "(60000, 28, 28)\n",
      "\n",
      "Traning Image dtype:\n",
      "uint8\n",
      "\n",
      "y_train:\n",
      "[5 0 4 ... 5 6 8]\n",
      "\n",
      "Traning Label Shape:\n",
      "(60000,)\n",
      "\n",
      "Traning Label dtype:\n",
      "uint8\n",
      "\n",
      "Skipping: print(\"x_test:\") print(x_test) print()\n",
      "\n",
      "Testing Image Shape:\n",
      "(10000, 28, 28)\n",
      "\n",
      "Testing Image dtype:\n",
      "uint8\n",
      "\n",
      "y_test:\n",
      "[7 2 1 ... 4 5 6]\n",
      "\n",
      "Testing Label Shape:\n",
      "(10000,)\n",
      "\n",
      "Testing Label dtype:\n",
      "uint8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Skipping: print(\"x_train:\") print(x_train) print()')\n",
    "#print(\"x_train:\") \n",
    "#print(x_train) \n",
    "#print()\n",
    "print()\n",
    "print(\"Traning Image Shape:\") \n",
    "print(x_train.shape) \n",
    "print()\n",
    "print(\"Traning Image dtype:\") \n",
    "print(x_train.dtype) \n",
    "print()\n",
    "print(\"y_train:\")\n",
    "print(y_train)\n",
    "print()\n",
    "print(\"Traning Label Shape:\")\n",
    "print(y_train.shape)\n",
    "print()\n",
    "print(\"Traning Label dtype:\")\n",
    "print(y_train.dtype)\n",
    "print()\n",
    "print('Skipping: print(\"x_test:\") print(x_test) print()')\n",
    "#print(\"x_test:\") \n",
    "#print(x_test) \n",
    "#print()\n",
    "print()\n",
    "print(\"Testing Image Shape:\")\n",
    "print(x_test.shape)\n",
    "print()\n",
    "print(\"Testing Image dtype:\")\n",
    "print(x_test.dtype)\n",
    "print()\n",
    "print(\"y_test:\")\n",
    "print(y_test)\n",
    "print()\n",
    "print(\"Testing Label Shape:\")\n",
    "print(y_test.shape)\n",
    "print()\n",
    "print(\"Testing Label dtype:\")\n",
    "print(y_test.dtype)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c8a2f-b03f-4e4d-85dc-8d3908c688e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Part 2:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eeafda3-67c3-4be0-9479-370b651cc7df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d360075-3a5e-44de-966b-71bc0e21c9da",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114b74c8-dd4c-4c03-8bd1-ca5daa44622f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045bafd5-501c-4695-ad59-1955dadfc6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.astype(\"float32\") / 255.0, x_test.astype(\"float32\") / 255.0\n",
    "#x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6657fd36-1c11-475d-9f7a-657c436932f3",
   "metadata": {},
   "source": [
    "## Model Selection, Tuning and Moitoring:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4febae1-0dca-4c82-8bfa-0f4af30527e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Create some example model defs (Intial Model Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e90c3372-b1d1-4063-aa1a-7e109ae3e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model(hidden):\n",
    "    return tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(hidden, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10, activation='softmax')])\n",
    "def get_model():\n",
    "    inputs = keras.Input(shape=(784,))\n",
    "    dense = layers.Dense(64, activation=\"relu\")\n",
    "    x = dense(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    return model\n",
    "def get_flat_model():\n",
    "    inputs = keras.Input(shape=(28, 28))\n",
    "    flat = keras.layers.Flatten(input_shape=(28, 28))(inputs)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(flat)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd4da68-d276-4504-ab7f-17f1e688a1f5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example 1: Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c277eff2-3c36-4297-bbd7-8841b83707b8",
   "metadata": {},
   "source": [
    "Create, Compile, Train, and Evaluate a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc9808fa-9e5e-4cd0-b0fa-7387522cfc4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 55050 (215.04 KB)\n",
      "Trainable params: 55050 (215.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "model = get_flat_model()\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "#model.fit(x=x_train, y=y_train, epochs=1, callbacks=[tensorboard_callback], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e9866d-1f88-4292-81ee-bfdf8fe9e480",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example 2: Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7ef8d9-49d6-4335-b116-eba48a09565d",
   "metadata": {},
   "source": [
    "Create, Compile, Train, and Evaluate a model for each hyperparameter configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d888bbbc-196b-4148-83a1-9e30ba878006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               200960    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 203530 (795.04 KB)\n",
      "Trainable params: 203530 (795.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "hidden_units=[256]#[64,128,256]\n",
    "\n",
    "for x in hidden_units:\n",
    "    model = mlp_model(x)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    #model.fit(x=x_train, y=y_train, epochs=1, callbacks=[tf.keras.callbacks.TensorBoard(log_dir=f\"logs/fit{x}/\"+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"), histogram_freq=1)], validation_split=0.2)\n",
    "    model.summary()\n",
    "\n",
    "    #probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "    #probability_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    #probability_model.evaluate(x_test, y_test, verbose=2)\n",
    "    #probability_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3608df-f60f-4a4f-a24c-7d8bf1bc7998",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Example 3: Expand tuning and tuning visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c304f8bc-05f6-4d9a-9f5c-74c56190c0bb",
   "metadata": {},
   "source": [
    "Create, Compile, Train, and Evaluate a model for each 'hp hyperparameter' Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afa2f729-07e5-41d1-867d-5f1121a86539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting trial: run-0\n",
      "{'num_units': 4, 'dropout': 0.0, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 1.0372 - accuracy: 0.6643 - val_loss: 0.6783 - val_accuracy: 0.7981\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6681 - accuracy: 0.8043 - val_loss: 0.6023 - val_accuracy: 0.8236\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6089 - accuracy: 0.8256 - val_loss: 0.5576 - val_accuracy: 0.8372\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5674 - accuracy: 0.8385 - val_loss: 0.5159 - val_accuracy: 0.8484\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5306 - accuracy: 0.8495 - val_loss: 0.4814 - val_accuracy: 0.8584\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5033 - accuracy: 0.8583 - val_loss: 0.4682 - val_accuracy: 0.8624\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4866 - accuracy: 0.8633 - val_loss: 0.4559 - val_accuracy: 0.8665\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4750 - accuracy: 0.8659 - val_loss: 0.4459 - val_accuracy: 0.8698\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.4689 - accuracy: 0.8681 - val_loss: 0.4393 - val_accuracy: 0.8700\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4628 - accuracy: 0.8699 - val_loss: 0.4360 - val_accuracy: 0.8717\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4580 - accuracy: 0.8720\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 3140      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3190 (12.46 KB)\n",
      "Trainable params: 3190 (12.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-1\n",
      "{'num_units': 4, 'dropout': 0.0, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.4082 - accuracy: 0.5601 - val_loss: 0.8471 - val_accuracy: 0.7621\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.7792 - accuracy: 0.7741 - val_loss: 0.6879 - val_accuracy: 0.8005\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.6885 - accuracy: 0.8009 - val_loss: 0.6323 - val_accuracy: 0.8198\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.6480 - accuracy: 0.8149 - val_loss: 0.6059 - val_accuracy: 0.8303\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6236 - accuracy: 0.8234 - val_loss: 0.5858 - val_accuracy: 0.8378\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6055 - accuracy: 0.8297 - val_loss: 0.5726 - val_accuracy: 0.8406\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5920 - accuracy: 0.8328 - val_loss: 0.5609 - val_accuracy: 0.8431\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5793 - accuracy: 0.8378 - val_loss: 0.5543 - val_accuracy: 0.8447\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5695 - accuracy: 0.8404 - val_loss: 0.5421 - val_accuracy: 0.8483\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5597 - accuracy: 0.8429 - val_loss: 0.5325 - val_accuracy: 0.8501\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.5403 - accuracy: 0.8463\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 4)                 3140      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3190 (12.46 KB)\n",
      "Trainable params: 3190 (12.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-2\n",
      "{'num_units': 4, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 1.5536 - accuracy: 0.4436 - val_loss: 1.0063 - val_accuracy: 0.7029\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.2413 - accuracy: 0.5655 - val_loss: 0.8464 - val_accuracy: 0.7700\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 1.1748 - accuracy: 0.6003 - val_loss: 0.7675 - val_accuracy: 0.8063\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.1491 - accuracy: 0.6146 - val_loss: 0.7391 - val_accuracy: 0.8291\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.1307 - accuracy: 0.6237 - val_loss: 0.7278 - val_accuracy: 0.8269\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.1165 - accuracy: 0.6275 - val_loss: 0.6997 - val_accuracy: 0.8356\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.1135 - accuracy: 0.6280 - val_loss: 0.6986 - val_accuracy: 0.8363\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 1.0916 - accuracy: 0.6344 - val_loss: 0.6846 - val_accuracy: 0.8408\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 1.1056 - accuracy: 0.6285 - val_loss: 0.6858 - val_accuracy: 0.8398\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 1.0902 - accuracy: 0.6329 - val_loss: 0.6718 - val_accuracy: 0.8429\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.6831 - accuracy: 0.8363\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_4 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 3140      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3190 (12.46 KB)\n",
      "Trainable params: 3190 (12.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-3\n",
      "{'num_units': 4, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.7857 - accuracy: 0.3954 - val_loss: 1.2968 - val_accuracy: 0.6488\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.4099 - accuracy: 0.5158 - val_loss: 1.0810 - val_accuracy: 0.6841\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.3230 - accuracy: 0.5399 - val_loss: 0.9999 - val_accuracy: 0.7119\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 1.2808 - accuracy: 0.5554 - val_loss: 0.9513 - val_accuracy: 0.7306\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.2572 - accuracy: 0.5616 - val_loss: 0.9081 - val_accuracy: 0.7358\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.2320 - accuracy: 0.5715 - val_loss: 0.8852 - val_accuracy: 0.7460\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.2139 - accuracy: 0.5794 - val_loss: 0.8379 - val_accuracy: 0.7715\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 1.1883 - accuracy: 0.5934 - val_loss: 0.8152 - val_accuracy: 0.7841\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.1646 - accuracy: 0.6044 - val_loss: 0.7863 - val_accuracy: 0.8007\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 1.1507 - accuracy: 0.6084 - val_loss: 0.7758 - val_accuracy: 0.8075\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.7824 - accuracy: 0.8040\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_5 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 4)                 3140      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 4)                 0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                50        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3190 (12.46 KB)\n",
      "Trainable params: 3190 (12.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-4\n",
      "{'num_units': 16, 'dropout': 0.0, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 7s 4ms/step - loss: 0.4993 - accuracy: 0.8622 - val_loss: 0.2851 - val_accuracy: 0.9217\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2770 - accuracy: 0.9227 - val_loss: 0.2416 - val_accuracy: 0.9328\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.2368 - accuracy: 0.9345 - val_loss: 0.2214 - val_accuracy: 0.9398\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.2112 - accuracy: 0.9410 - val_loss: 0.2048 - val_accuracy: 0.9436\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1933 - accuracy: 0.9460 - val_loss: 0.1969 - val_accuracy: 0.9435\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1788 - accuracy: 0.9493 - val_loss: 0.1893 - val_accuracy: 0.9452\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.1691 - accuracy: 0.9525 - val_loss: 0.1834 - val_accuracy: 0.9492\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1598 - accuracy: 0.9549 - val_loss: 0.1794 - val_accuracy: 0.9489\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1530 - accuracy: 0.9559 - val_loss: 0.1804 - val_accuracy: 0.9493\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1459 - accuracy: 0.9575 - val_loss: 0.1701 - val_accuracy: 0.9511\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1752 - accuracy: 0.9522\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_6 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 16)                12560     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12730 (49.73 KB)\n",
      "Trainable params: 12730 (49.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-5\n",
      "{'num_units': 16, 'dropout': 0.0, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.9460 - accuracy: 0.7410 - val_loss: 0.4407 - val_accuracy: 0.8854\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4117 - accuracy: 0.8878 - val_loss: 0.3452 - val_accuracy: 0.9040\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3483 - accuracy: 0.9025 - val_loss: 0.3134 - val_accuracy: 0.9134\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3181 - accuracy: 0.9114 - val_loss: 0.2938 - val_accuracy: 0.9188\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2980 - accuracy: 0.9167 - val_loss: 0.2763 - val_accuracy: 0.9235\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2829 - accuracy: 0.9207 - val_loss: 0.2651 - val_accuracy: 0.9275\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2713 - accuracy: 0.9241 - val_loss: 0.2568 - val_accuracy: 0.9298\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2615 - accuracy: 0.9276 - val_loss: 0.2484 - val_accuracy: 0.9320\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2530 - accuracy: 0.9299 - val_loss: 0.2430 - val_accuracy: 0.9345\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.2459 - accuracy: 0.9316 - val_loss: 0.2381 - val_accuracy: 0.9352\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2422 - accuracy: 0.9340\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_7 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 16)                12560     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12730 (49.73 KB)\n",
      "Trainable params: 12730 (49.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-6\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 8s 4ms/step - loss: 0.7027 - accuracy: 0.7839 - val_loss: 0.3053 - val_accuracy: 0.9183\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4598 - accuracy: 0.8569 - val_loss: 0.2624 - val_accuracy: 0.9290\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.4168 - accuracy: 0.8716 - val_loss: 0.2521 - val_accuracy: 0.9297\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.3919 - accuracy: 0.8777 - val_loss: 0.2359 - val_accuracy: 0.9355\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3760 - accuracy: 0.8819 - val_loss: 0.2276 - val_accuracy: 0.9365\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3626 - accuracy: 0.8872 - val_loss: 0.2212 - val_accuracy: 0.9390\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.3538 - accuracy: 0.8875 - val_loss: 0.2156 - val_accuracy: 0.9410\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3442 - accuracy: 0.8919 - val_loss: 0.2157 - val_accuracy: 0.9373\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3386 - accuracy: 0.8942 - val_loss: 0.2133 - val_accuracy: 0.9394\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.3324 - accuracy: 0.8947 - val_loss: 0.2056 - val_accuracy: 0.9415\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2035 - accuracy: 0.9406\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_8 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 16)                12560     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12730 (49.73 KB)\n",
      "Trainable params: 12730 (49.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-7\n",
      "{'num_units': 16, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 6s 3ms/step - loss: 1.0953 - accuracy: 0.6499 - val_loss: 0.5263 - val_accuracy: 0.8741\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.6635 - accuracy: 0.7951 - val_loss: 0.4073 - val_accuracy: 0.8958\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5802 - accuracy: 0.8209 - val_loss: 0.3630 - val_accuracy: 0.9046\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.5300 - accuracy: 0.8348 - val_loss: 0.3344 - val_accuracy: 0.9115\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4975 - accuracy: 0.8470 - val_loss: 0.3131 - val_accuracy: 0.9159\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4788 - accuracy: 0.8529 - val_loss: 0.3039 - val_accuracy: 0.9181\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.4617 - accuracy: 0.8584 - val_loss: 0.2916 - val_accuracy: 0.9204\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 5s 4ms/step - loss: 0.4454 - accuracy: 0.8609 - val_loss: 0.2810 - val_accuracy: 0.9239\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 5s 3ms/step - loss: 0.4351 - accuracy: 0.8655 - val_loss: 0.2756 - val_accuracy: 0.9255\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.4283 - accuracy: 0.8675 - val_loss: 0.2694 - val_accuracy: 0.9272\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2705 - accuracy: 0.9239\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_9 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                12560     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 12730 (49.73 KB)\n",
      "Trainable params: 12730 (49.73 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-8\n",
      "{'num_units': 64, 'dropout': 0.0, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3288 - accuracy: 0.9078 - val_loss: 0.1934 - val_accuracy: 0.9424\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1623 - accuracy: 0.9528 - val_loss: 0.1414 - val_accuracy: 0.9589\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.1220 - accuracy: 0.9633 - val_loss: 0.1285 - val_accuracy: 0.9623\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.0966 - accuracy: 0.9721 - val_loss: 0.1094 - val_accuracy: 0.9669\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0794 - accuracy: 0.9758 - val_loss: 0.1195 - val_accuracy: 0.9659\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0666 - accuracy: 0.9796 - val_loss: 0.1055 - val_accuracy: 0.9687\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0560 - accuracy: 0.9833 - val_loss: 0.1056 - val_accuracy: 0.9698\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0497 - accuracy: 0.9849 - val_loss: 0.0977 - val_accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 6s 4ms/step - loss: 0.0418 - accuracy: 0.9871 - val_loss: 0.1050 - val_accuracy: 0.9701\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.0363 - accuracy: 0.9891 - val_loss: 0.1024 - val_accuracy: 0.9728\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9726\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_10 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-9\n",
      "{'num_units': 64, 'dropout': 0.0, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 7s 5ms/step - loss: 0.7176 - accuracy: 0.8211 - val_loss: 0.3779 - val_accuracy: 0.9003\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3649 - accuracy: 0.8991 - val_loss: 0.3094 - val_accuracy: 0.9128\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.3131 - accuracy: 0.9117 - val_loss: 0.2799 - val_accuracy: 0.9200\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2837 - accuracy: 0.9200 - val_loss: 0.2592 - val_accuracy: 0.9260\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2626 - accuracy: 0.9254 - val_loss: 0.2434 - val_accuracy: 0.9318\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2458 - accuracy: 0.9308 - val_loss: 0.2298 - val_accuracy: 0.9355\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2315 - accuracy: 0.9345 - val_loss: 0.2190 - val_accuracy: 0.9377\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2193 - accuracy: 0.9378 - val_loss: 0.2108 - val_accuracy: 0.9405\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2087 - accuracy: 0.9405 - val_loss: 0.2014 - val_accuracy: 0.9442\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.1996 - accuracy: 0.9429 - val_loss: 0.1953 - val_accuracy: 0.9452\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1947 - accuracy: 0.9458\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_11 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-10\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'adam'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 10s 6ms/step - loss: 0.3990 - accuracy: 0.8833 - val_loss: 0.1907 - val_accuracy: 0.9456\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2090 - accuracy: 0.9384 - val_loss: 0.1399 - val_accuracy: 0.9592\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1655 - accuracy: 0.9509 - val_loss: 0.1202 - val_accuracy: 0.9644\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1429 - accuracy: 0.9571 - val_loss: 0.1097 - val_accuracy: 0.9676\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.1241 - accuracy: 0.9614 - val_loss: 0.1021 - val_accuracy: 0.9704\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1129 - accuracy: 0.9641 - val_loss: 0.1073 - val_accuracy: 0.9685\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1045 - accuracy: 0.9669 - val_loss: 0.0964 - val_accuracy: 0.9713\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.0964 - accuracy: 0.9696 - val_loss: 0.0988 - val_accuracy: 0.9722\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0919 - accuracy: 0.9716 - val_loss: 0.0955 - val_accuracy: 0.9736\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0877 - accuracy: 0.9717 - val_loss: 0.0895 - val_accuracy: 0.9755\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0850 - accuracy: 0.9742\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_12 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "--- Starting trial: run-11\n",
      "{'num_units': 64, 'dropout': 0.2, 'optimizer': 'sgd'}\n",
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.8303 - accuracy: 0.7684 - val_loss: 0.4024 - val_accuracy: 0.8965\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.4539 - accuracy: 0.8692 - val_loss: 0.3235 - val_accuracy: 0.9107\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3877 - accuracy: 0.8887 - val_loss: 0.2881 - val_accuracy: 0.9197\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3461 - accuracy: 0.9006 - val_loss: 0.2635 - val_accuracy: 0.9249\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.3194 - accuracy: 0.9086 - val_loss: 0.2452 - val_accuracy: 0.9309\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2972 - accuracy: 0.9139 - val_loss: 0.2291 - val_accuracy: 0.9362\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2788 - accuracy: 0.9198 - val_loss: 0.2162 - val_accuracy: 0.9396\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2641 - accuracy: 0.9236 - val_loss: 0.2054 - val_accuracy: 0.9424\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 8s 6ms/step - loss: 0.2534 - accuracy: 0.9279 - val_loss: 0.1972 - val_accuracy: 0.9445\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.2418 - accuracy: 0.9309 - val_loss: 0.1894 - val_accuracy: 0.9477\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.1925 - accuracy: 0.9454\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_13 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50890 (198.79 KB)\n",
      "Trainable params: 50890 (198.79 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating Hparams\n",
    "#HP_NUM_LAYERS = hp.HParam('num_layers', hp.Discrete([1, 2]))\n",
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([4, 16, 64]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.2))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['sgd','adam'])) \n",
    "\n",
    "# Creating train test function\n",
    "def train_test_model(hparams, run_dir):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(hparams[HP_NUM_UNITS], activation=tf.nn.relu),\n",
    "        tf.keras.layers.Dropout(hparams[HP_DROPOUT]),\n",
    "        tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER],loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "    callbacks = [tf.keras.callbacks.TensorBoard(run_dir), hp.KerasCallback(run_dir, hparams), ]# log metrics, log hparams\n",
    "    model.fit(x_train, y_train, epochs=10, callbacks = callbacks, validation_split=0.2) # Run with 1 epoch to speed things up for demo purposes\n",
    "    _, accuracy = model.evaluate(x_test, y_test)\n",
    "    model.summary()\n",
    "    return accuracy \n",
    "\n",
    "session_num = 0\n",
    "for num_units in HP_NUM_UNITS.domain.values:\n",
    "    for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "            hparams = {HP_NUM_UNITS: num_units, HP_DROPOUT: dropout_rate, HP_OPTIMIZER: optimizer,}\n",
    "            run_name = \"run-%d\" % session_num\n",
    "            print('--- Starting trial: %s' % run_name)\n",
    "            print({h.name: hparams[h] for h in hparams})\n",
    "            train_test_model(hparams, 'logs/hparam_tuning/' + run_name)\n",
    "            session_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e2b0fc-4e44-4133-ab04-6b99e0a6a7eb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Monitoring with Tensorboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9e2cf92-78c5-46c4-8ea7-1cfe31c7c107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e032de5ca26399a4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e032de5ca26399a4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6009"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbcd8674-1853-49b1-998a-38384024fef2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Initial Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f4a767-44ca-41cb-887c-3c6146f83921",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2930813-4c6f-4b62-b2af-fdb0f36bc94f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## A/B testing for detecting Data Drift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a38db0-2d2a-43e7-aa01-75b8d6a8c44d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Evaluate Strata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42c32fc-9a2c-4e35-a9a1-4c1a5ed719da",
   "metadata": {},
   "source": [
    "Examples of Stratas:\n",
    "- Data sources\n",
    "- label source\n",
    "- Sex\n",
    "- race\n",
    "- age\n",
    "\n",
    "Task:\n",
    "- split val set into subsets based on strata meta info or use a dataset from a diferent strata from the original train and val set. \n",
    "- a/b testing via evaluations with the new datasets or subsets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2f350f-fcca-46bb-9aa1-224ff1d9a756",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Serving and Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e046e8-a31f-4855-a329-45ee4d986e04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56df24b5-7b29-42b1-a990-1c58907b7b05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Development Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4561904-f720-4664-8429-e96a508cdcb4",
   "metadata": {},
   "source": [
    "## 1. Hard code a bare bones proof-of-concept (POC) for an ML Project, within the identified project scope, in a single jupyter notebook file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ee7ae3-9bf0-45f9-8e60-43e54abb09b4",
   "metadata": {},
   "source": [
    "## 2. Define functions for repeatable lines of code, define variables for controling previously hardcoded settings,improve naming conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f06d301-dfa5-4976-8419-560b103dae9d",
   "metadata": {},
   "source": [
    "## 3. Add variables to control previously hard coded settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf24470-6c58-4cee-9aad-e2ea9742a066",
   "metadata": {},
   "source": [
    "## 4. move functions into seperate files to shorten and siplify the main file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7b0cb3-e2e2-44c1-b475-b81659261acd",
   "metadata": {},
   "source": [
    "## 5. Add or update Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3de17e-e325-462d-876d-b1092b90d50f",
   "metadata": {},
   "source": [
    "## 6. Add more Features to the project That are relavent to the identified project scope starting from step one if more improvements are needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57bdf0d-2c6b-45f6-8d43-0c5dce1174a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Project Management Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7523d5-f05e-4893-9f26-42fb2a25acb1",
   "metadata": {},
   "source": [
    "## Setup a Project Dashboard for the github repo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df782261-02ce-4dea-93f9-43509c91f809",
   "metadata": {},
   "source": [
    "## add meaningful views to the dashboard to help orginize the project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b0d97-0f67-4aa0-a4a9-770d2ea972a8",
   "metadata": {},
   "source": [
    "## setup auto email alerts for team members assigned to issues when updates are posted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859aa78-fb76-4bd1-bd25-d12bbcd6f010",
   "metadata": {},
   "source": [
    "## Add issues and set the priority, size, sprint, labels, tags, and more if needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b49c7-1f95-4225-8bf6-90e1f8a53feb",
   "metadata": {},
   "source": [
    "## Set and enforce standards for team members posting to the project dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8a76c5-8a44-40b5-87d5-5d20b691f20c",
   "metadata": {},
   "source": [
    "## Set Rules for the repo to protect the main branch from updates without reviews from more than one person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4329fe9-a190-4405-90b2-afe581ef81ff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Manually assign project issues for team members to work on or allow self assigning issues for a more hands free approach to managing the team."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fda291-e728-414a-8ded-cd9dccb98da8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Regularly sceduled meetings with your team and with other managers from other departments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e624abfb-e3bb-48cf-8c82-bcbfd816c789",
   "metadata": {},
   "source": [
    "- Management Meetings\n",
    "    - discus customer concerns and requests\n",
    "    - discus internal questions and concerns related to budgetting, time lines, security, legal, ect.\n",
    "    - re-evaluate project issue priorities and sceduled sprints as a group.\n",
    "- Team Meating\n",
    "    - Summary of major updates\n",
    "    - Point out examples of good work from the team \n",
    "    - Point out common mistakes that more than one team member is made without speciffing who made the mistake\n",
    "- Member meetings\n",
    "    - Discus progress and personal growth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c805f354-a649-4236-bfc2-998b4fe6ef54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Allways encourage team members to ask questions for clarity on the goal of a tasks and to ask for more directions if they get stuck."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5193142d-e863-4a20-b449-cbd4ee52ca5d",
   "metadata": {},
   "source": [
    "- Try to respond to the questions in a way that helps them build the intuition to find the answers to similar questions themselves next time.\n",
    "- Try to identify the way they were confused by the task and help them understand how to frame the problem better in thier mind by asking the right question.\n",
    "- Time spent fostering growth among jonior team members instead of just solving the problem for them promotes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f2defa-e533-4a98-a7fb-293a5cdaea3d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Download and load the cifar10 Dataset\n",
    "## Preprocess\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af8bc8fb-9b4e-4508-98a7-44f159b1065e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\gilbr\\ML_Proj_Code\\Proj_1_venv\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img (InputLayer)            [(None, 32, 32, 3)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 30, 30, 32)           896       ['img[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 28, 28, 64)           18496     ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 9, 9, 64)             0         ['conv2d_1[0][0]']            \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 9, 9, 64)             36928     ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 9, 9, 64)             36928     ['conv2d_2[0][0]']            \n",
      "                                                                                                  \n",
      " add (Add)                   (None, 9, 9, 64)             0         ['conv2d_3[0][0]',            \n",
      "                                                                     'max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 9, 9, 64)             36928     ['add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 9, 9, 64)             36928     ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " add_1 (Add)                 (None, 9, 9, 64)             0         ['conv2d_5[0][0]',            \n",
      "                                                                     'add[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 7, 7, 64)             36928     ['add_1[0][0]']               \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 64)                   0         ['conv2d_6[0][0]']            \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense_41 (Dense)            (None, 256)                  16640     ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, 256)                  0         ['dense_41[0][0]']            \n",
      "                                                                                                  \n",
      " dense_42 (Dense)            (None, 10)                   2570      ['dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 223242 (872.04 KB)\n",
      "Trainable params: 223242 (872.04 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train, x_test = x_train.astype(\"float32\") / 255.0, x_test.astype(\"float32\") / 255.0\n",
    "y_train, y_test = keras.utils.to_categorical(y_train, 10), keras.utils.to_categorical(y_test, 10)\n",
    "def get_mini_resnet():\n",
    "    inputs = keras.Input(shape=(32, 32, 3), name=\"img\")\n",
    "    x = layers.Conv2D(32, 3, activation=\"relu\")(inputs)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(x)\n",
    "    block_1_output = layers.MaxPooling2D(3)(x)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_1_output)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    block_2_output = layers.add([x, block_1_output])\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(block_2_output)\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "    block_3_output = layers.add([x, block_2_output])\n",
    "    x = layers.Conv2D(64, 3, activation=\"relu\")(block_3_output)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(10)(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    return model\n",
    "model = get_mini_resnet()\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(1e-3), loss=keras.losses.CategoricalCrossentropy(from_logits=True), metrics=[\"acc\"],)\n",
    "#model.fit(x_train, y_train, batch_size=64, epochs=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d168e5d3-346e-4980-ba1f-9c8f691de230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv4 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv4 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv4 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 143667240 (548.05 MB)\n",
      "Trainable params: 143667240 (548.05 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg19 = keras.applications.VGG19()\n",
    "vgg19.summary()\n",
    "features_list = [layer.output for layer in vgg19.layers]\n",
    "feat_extraction_model = keras.Model(inputs=vgg19.input, outputs=features_list)\n",
    "img = np.random.random((1, 224, 224, 3)).astype(\"float32\")\n",
    "extracted_features = feat_extraction_model(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53580fea-b767-4e15-8295-d369b82ea09b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Autoencoder: Encoder + Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef66764e-6b87-4ac9-8554-0a6d0371ea62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 16)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18672 (72.94 KB)\n",
      "Trainable params: 18672 (72.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d (Glob  (None, 16)                0         \n",
      " alMaxPooling2D)                                                 \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 4, 4, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 6, 6, 16)          160       \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 8, 8, 32)          4640      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " up_sampling2d (UpSampling2  (None, 24, 24, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 26, 26, 16)        4624      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2D  (None, 28, 28, 1)         145       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28241 (110.32 KB)\n",
      "Trainable params: 28241 (110.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fd4e972-8608-4768-bdfc-357a207999c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " original_img (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 26, 26, 16)        160       \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 24, 24, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 8, 8, 32)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 6, 6, 32)          9248      \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 4, 4, 16)          4624      \n",
      "                                                                 \n",
      " global_max_pooling2d_1 (Gl  (None, 16)                0         \n",
      " obalMaxPooling2D)                                               \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18672 (72.94 KB)\n",
      "Trainable params: 18672 (72.94 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoded_img (InputLayer)    [(None, 16)]              0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 4, 4, 1)           0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2D  (None, 6, 6, 16)          160       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2D  (None, 8, 8, 32)          4640      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSamplin  (None, 24, 24, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_transpose_6 (Conv2D  (None, 26, 26, 16)        4624      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " conv2d_transpose_7 (Conv2D  (None, 28, 28, 1)         145       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9569 (37.38 KB)\n",
      "Trainable params: 9569 (37.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder (Functional)        (None, 16)                18672     \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 28, 28, 1)         9569      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 28241 (110.32 KB)\n",
      "Trainable params: 28241 (110.32 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder_input = keras.Input(shape=(28, 28, 1), name=\"original_img\")\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(encoder_input)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(3)(x)\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(16, 3, activation=\"relu\")(x)\n",
    "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "encoder.summary()\n",
    "\n",
    "decoder_input = keras.Input(shape=(16,), name=\"encoded_img\")\n",
    "x = layers.Reshape((4, 4, 1))(decoder_input)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\")(x)\n",
    "x = layers.UpSampling2D(3)(x)\n",
    "x = layers.Conv2DTranspose(16, 3, activation=\"relu\")(x)\n",
    "decoder_output = layers.Conv2DTranspose(1, 3, activation=\"relu\")(x)\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "decoder.summary()\n",
    "\n",
    "autoencoder_input = keras.Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoded_img = encoder(autoencoder_input)\n",
    "decoded_img = decoder(encoded_img)\n",
    "autoencoder = keras.Model(autoencoder_input, decoded_img, name=\"autoencoder\")\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db950dd-2d8e-4609-82b4-fcb0cabe5a0a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Multi Input and Multi Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef76986-cf82-410b-81f3-7e306b8156fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " title (InputLayer)          [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " body (InputLayer)           [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 64)             640000    ['title[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 64)             640000    ['body[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 128)                  98816     ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 32)                   12416     ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " tags (InputLayer)           [(None, 12)]                 0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 172)                  0         ['lstm[0][0]',                \n",
      "                                                                     'lstm_1[0][0]',              \n",
      "                                                                     'tags[0][0]']                \n",
      "                                                                                                  \n",
      " priority (Dense)            (None, 1)                    173       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " department (Dense)          (None, 4)                    692       ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1392097 (5.31 MB)\n",
      "Trainable params: 1392097 (5.31 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_tags = 12  # Number of unique issue tags\n",
    "num_words = 10000  # Size of vocabulary obtained when preprocessing text data\n",
    "num_departments = 4  # Number of departments for predictions\n",
    "\n",
    "title_input = keras.Input(shape=(None,), name=\"title\")  # Variable-length sequence of ints\n",
    "body_input = keras.Input(shape=(None,), name=\"body\")  # Variable-length sequence of ints\n",
    "tags_input = keras.Input(shape=(num_tags,), name=\"tags\")  # Binary vectors of size `num_tags`\n",
    "\n",
    "# Embed each word in the title into a 64-dimensional vector\n",
    "title_features = layers.Embedding(num_words, 64)(title_input)\n",
    "# Embed each word in the text into a 64-dimensional vector\n",
    "body_features = layers.Embedding(num_words, 64)(body_input)\n",
    "\n",
    "# Reduce sequence of embedded words in the title into a single 128-dimensional vector\n",
    "title_features = layers.LSTM(128)(title_features)\n",
    "# Reduce sequence of embedded words in the body into a single 32-dimensional vector\n",
    "body_features = layers.LSTM(32)(body_features)\n",
    "\n",
    "# Merge all available features into a single large vector via concatenation\n",
    "x = layers.concatenate([title_features, body_features, tags_input])\n",
    "\n",
    "# Stick a logistic regression for priority prediction on top of the features\n",
    "priority_pred = layers.Dense(1, name=\"priority\")(x)\n",
    "# Stick a department classifier on top of the features\n",
    "department_pred = layers.Dense(num_departments, name=\"department\")(x)\n",
    "\n",
    "# Instantiate an end-to-end model predicting both priority and department\n",
    "model = keras.Model(\n",
    "    inputs=[title_input, body_input, tags_input],\n",
    "    outputs=[priority_pred, department_pred],)\n",
    "\n",
    "if True:\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "        loss=[keras.losses.BinaryCrossentropy(from_logits=True),keras.losses.CategoricalCrossentropy(from_logits=True),],\n",
    "        loss_weights=[1.0, 0.2],)\n",
    "else:\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "        loss={\"priority\": keras.losses.BinaryCrossentropy(from_logits=True),\"department\": keras.losses.CategoricalCrossentropy(from_logits=True),},\n",
    "        loss_weights={\"priority\": 1.0, \"department\": 0.2},)\n",
    "# Dummy input data\n",
    "title_data = np.random.randint(num_words, size=(1280, 10))\n",
    "body_data = np.random.randint(num_words, size=(1280, 100))\n",
    "tags_data = np.random.randint(2, size=(1280, num_tags)).astype(\"float32\")\n",
    "# Dummy target data\n",
    "priority_targets = np.random.random(size=(1280, 1))\n",
    "dept_targets = np.random.randint(2, size=(1280, num_departments))\n",
    "\n",
    "#model.fit({\"title\": title_data, \"body\": body_data, \"tags\": tags_data}, {\"priority\": priority_targets, \"department\": dept_targets}, epochs=2, batch_size=32,)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586169a7-774f-41f6-871c-4ec27ccdacde",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "583dfe85-89cc-4cfc-8bfa-cec7932f25b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding for 1000 unique words mapped to 128-dimensional vectors\n",
    "shared_embedding = layers.Embedding(1000, 128)\n",
    "\n",
    "# Variable-length sequences of integers\n",
    "text_input_a = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "text_input_b = keras.Input(shape=(None,), dtype=\"int32\")\n",
    "\n",
    "# Reuse the same layer to encode both inputs\n",
    "encoded_input_a = shared_embedding(text_input_a)\n",
    "encoded_input_b = shared_embedding(text_input_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c9acc9-2878-4a6e-b5ed-0b0ca59b40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57d54de6-f0e1-432d-86db-2badc9bc172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_iris,load_diabetes,load_digits,load_linnerud,load_wine,load_breast_cancer\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ca92ae-b4c1-469a-909e-5f0af8178784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e15ba4-787c-4571-a855-1bd9be3e362f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee9e070-c8be-4c52-b1c6-3daed0416170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea17d1-cd0d-48ef-a508-737e9538a116",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f802b8-4661-4def-8a17-91835905685b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf67ea17-7aee-43f7-a724-7ffa42ba4f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
